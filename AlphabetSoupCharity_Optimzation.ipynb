{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "index                                                           \n",
       "0           1     5000              1                     0.0   \n",
       "1           1   108590              1                     0.0   \n",
       "2           1     5000              0                     0.0   \n",
       "3           1     6692              1                     0.0   \n",
       "4           1   142590              1                     0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "index                                                                    \n",
       "0                       1.0                   0.0                  0.0   \n",
       "1                       0.0                   0.0                  1.0   \n",
       "2                       0.0                   0.0                  0.0   \n",
       "3                       0.0                   0.0                  1.0   \n",
       "4                       0.0                   0.0                  1.0   \n",
       "\n",
       "       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "index                                                                 ...   \n",
       "0                      0.0                  0.0                  0.0  ...   \n",
       "1                      0.0                  0.0                  0.0  ...   \n",
       "2                      0.0                  1.0                  0.0  ...   \n",
       "3                      0.0                  0.0                  0.0  ...   \n",
       "4                      0.0                  0.0                  0.0  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "index                                                                        \n",
       "0                    0.0                     0.0                       0.0   \n",
       "1                    1.0                     0.0                       0.0   \n",
       "2                    0.0                     0.0                       0.0   \n",
       "3                    0.0                     1.0                       0.0   \n",
       "4                    0.0                     0.0                       1.0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "index                                                                 \n",
       "0                     0.0               0.0                     0.0   \n",
       "1                     0.0               0.0                     0.0   \n",
       "2                     0.0               0.0                     0.0   \n",
       "3                     0.0               0.0                     0.0   \n",
       "4                     0.0               0.0                     0.0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "index                                                                 \n",
       "0                  0.0                0.0                       1.0   \n",
       "1                  0.0                0.0                       1.0   \n",
       "2                  0.0                0.0                       1.0   \n",
       "3                  0.0                0.0                       1.0   \n",
       "4                  0.0                0.0                       1.0   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "index                            \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "dbpath = \"postgresql://postgres@localhost:5432/asoup\"\n",
    "engine = create_engine(dbpath)\n",
    "encoded_df = pd.read_sql(\"SELECT * FROM clean_data\", engine).set_index(\"index\")\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "We want to get rid of outliers, make sure data is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.429900e+04\n",
       "mean     2.769199e+06\n",
       "std      8.713045e+07\n",
       "min      5.000000e+03\n",
       "25%      5.000000e+03\n",
       "50%      5.000000e+03\n",
       "75%      7.742000e+03\n",
       "max      8.597806e+09\n",
       "Name: ASK_AMT, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_amount = encoded_df[\"ASK_AMT\"]\n",
    "plt.boxplot(ask_amount)\n",
    "ask_amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for organizing outliers data\n",
    "def get_outliers_data(data: pd.Series, lower: float, upper: float) -> dict:\n",
    "    \"\"\"Returns a dictionary with the upper, lower limits, number and percentage of outliers.\"\"\"\n",
    "    outliers = data[(data < lower) | (data >= upper)]\n",
    "    n_outliers = outliers.count()\n",
    "    return outliers, {\n",
    "        \"upper_limit\": upper,\n",
    "        \"lower_limit\": lower,\n",
    "        \"n_outliers\": n_outliers, \n",
    "        \"percentage\": f\"{100* n_outliers / ask_amount.count():.2f}%\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upper_limit': 11855.0,\n",
       " 'lower_limit': 887.0,\n",
       " 'n_outliers': 8206,\n",
       " 'percentage': '23.92%'}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using IQR\n",
    "q1 = ask_amount.quantile(0.25)\n",
    "q3 = ask_amount.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "outliers_iqr, outliers_iqr_data = get_outliers_data(ask_amount, q1 - 1.5*iqr, q3 + 1.5*iqr)\n",
    "outliers_iqr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upper_limit': 177030103.5539489,\n",
       " 'lower_limit': -171491706.18982753,\n",
       " 'n_outliers': 80,\n",
       " 'percentage': '0.23%'}"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using STD\n",
    "std = ask_amount.std()\n",
    "mean = ask_amount.mean()\n",
    "outliers_std, outliers_std_data = get_outliers_data(ask_amount, mean - std*2, mean + std*2)\n",
    "outliers_std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13b6a7c10>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clustering with 2 dimensions of data\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "X = encoded_df[[\"ASK_AMT\", \"STATUS\"]]\n",
    "X_scaled = MinMaxScaler().fit_transform(X.values)\n",
    "sse = pd.Series({k: KMeans(n_clusters=k).fit(X_scaled).inertia_ for k in range(1, 10)})\n",
    "plt.plot(sse.index, sse.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    34261\n",
      "3       29\n",
      "1        5\n",
      "2        4\n",
      "Name: Cluster, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upper_limit': 1, 'lower_limit': 0, 'n_outliers': 38, 'percentage': '0.11%'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster data\n",
    "model = KMeans(n_clusters=4, random_state=1).fit(X_scaled)\n",
    "combined = encoded_df.copy(deep=True)\n",
    "combined[\"Cluster\"] = model.predict(X_scaled)\n",
    "print(combined[\"Cluster\"].value_counts())\n",
    "outliers_kmeans, outliers_kmeans_data = get_outliers_data(combined[\"Cluster\"], 0, 1) # excluding lower and including upper\n",
    "outliers_kmeans_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IQR</th>\n",
       "      <th>STD</th>\n",
       "      <th>KMeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>upper_limit</th>\n",
       "      <td>11855.0</td>\n",
       "      <td>177030103.553949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lower_limit</th>\n",
       "      <td>887.0</td>\n",
       "      <td>-171491706.189828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_outliers</th>\n",
       "      <td>8206</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage</th>\n",
       "      <td>23.92%</td>\n",
       "      <td>0.23%</td>\n",
       "      <td>0.11%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 IQR               STD KMeans\n",
       "upper_limit  11855.0  177030103.553949      1\n",
       "lower_limit    887.0 -171491706.189828      0\n",
       "n_outliers      8206                80     38\n",
       "percentage    23.92%             0.23%  0.11%"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"IQR\": outliers_iqr_data, \"STD\": outliers_std_data, \"KMeans\": outliers_kmeans_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Filtering # 1\n",
    "We are going to go with the data without the STD outliers as the percentage looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25664, 43), (8555, 43))"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the Data\n",
    "df = encoded_df.drop(outliers_std.index)\n",
    "y = df[\"IS_SUCCESSFUL\"].values\n",
    "X = df.drop([\"IS_SUCCESSFUL\"], axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 40)                1760      \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,601\n",
      "Trainable params: 2,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Replicating the previous model\n",
    "nn_a = tf.keras.models.Sequential()\n",
    "nn_a.add(tf.keras.layers.Dense(units=40, activation=\"relu\", input_dim=len(X_train_scaled[0])))\n",
    "nn_a.add(tf.keras.layers.Dense(units=20, activation=\"relu\"))\n",
    "nn_a.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "nn_a.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "nn_a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5735 - accuracy: 0.7180\n",
      "Epoch 2/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5558 - accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5530 - accuracy: 0.7295\n",
      "Epoch 4/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.7309\n",
      "Epoch 5/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5500 - accuracy: 0.7324\n",
      "Epoch 6/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5486 - accuracy: 0.7321\n",
      "Epoch 7/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7320\n",
      "Epoch 8/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.7318\n",
      "Epoch 9/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5474 - accuracy: 0.7324\n",
      "Epoch 10/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5465 - accuracy: 0.7327\n",
      "Epoch 11/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5462 - accuracy: 0.7339\n",
      "Epoch 12/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7346\n",
      "Epoch 13/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7350\n",
      "Epoch 14/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7340\n",
      "Epoch 15/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7354\n",
      "Epoch 16/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7335\n",
      "Epoch 17/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7344\n",
      "Epoch 18/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7336\n",
      "Epoch 19/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7354\n",
      "Epoch 20/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7359\n",
      "Epoch 21/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7352\n",
      "Epoch 22/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7351\n",
      "Epoch 23/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7356\n",
      "Epoch 24/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7354\n",
      "Epoch 25/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7369\n",
      "Epoch 26/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7355\n",
      "Epoch 27/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7356\n",
      "Epoch 28/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5412 - accuracy: 0.7376\n",
      "Epoch 29/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7371\n",
      "Epoch 30/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7373\n",
      "Epoch 31/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7380\n",
      "Epoch 32/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7375\n",
      "Epoch 33/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7371\n",
      "Epoch 34/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7375\n",
      "Epoch 35/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5403 - accuracy: 0.7376\n",
      "Epoch 36/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7380\n",
      "Epoch 37/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5403 - accuracy: 0.7368\n",
      "Epoch 38/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7385\n",
      "Epoch 39/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7372\n",
      "Epoch 40/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7373\n",
      "Epoch 41/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5394 - accuracy: 0.7375\n",
      "Epoch 42/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7383\n",
      "Epoch 43/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5388 - accuracy: 0.7391\n",
      "Epoch 44/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7396\n",
      "Epoch 45/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5392 - accuracy: 0.7375\n",
      "Epoch 46/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7377\n",
      "Epoch 47/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7401\n",
      "Epoch 48/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7382\n",
      "Epoch 49/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7381\n",
      "Epoch 50/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7389\n",
      "Epoch 51/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7393\n",
      "Epoch 52/100\n",
      "802/802 [==============================] - 2s 3ms/step - loss: 0.5387 - accuracy: 0.7387\n",
      "Epoch 53/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7394\n",
      "Epoch 54/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7392\n",
      "Epoch 55/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7382\n",
      "Epoch 56/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7391\n",
      "Epoch 57/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7388\n",
      "Epoch 58/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7401\n",
      "Epoch 59/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7392\n",
      "Epoch 60/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7392\n",
      "Epoch 61/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7402\n",
      "Epoch 62/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7389\n",
      "Epoch 63/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7397\n",
      "Epoch 64/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7397\n",
      "Epoch 65/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7396\n",
      "Epoch 66/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7393\n",
      "Epoch 67/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7399\n",
      "Epoch 68/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7396\n",
      "Epoch 69/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7386\n",
      "Epoch 70/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7384\n",
      "Epoch 71/100\n",
      "802/802 [==============================] - 2s 3ms/step - loss: 0.5371 - accuracy: 0.7399\n",
      "Epoch 72/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7396\n",
      "Epoch 73/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7401\n",
      "Epoch 74/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7403\n",
      "Epoch 75/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7410\n",
      "Epoch 76/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7397\n",
      "Epoch 77/100\n",
      "802/802 [==============================] - 2s 3ms/step - loss: 0.5367 - accuracy: 0.7401\n",
      "Epoch 78/100\n",
      "802/802 [==============================] - 3s 4ms/step - loss: 0.5364 - accuracy: 0.7395\n",
      "Epoch 79/100\n",
      "802/802 [==============================] - 3s 4ms/step - loss: 0.5361 - accuracy: 0.7406\n",
      "Epoch 80/100\n",
      "802/802 [==============================] - 4s 5ms/step - loss: 0.5364 - accuracy: 0.7404\n",
      "Epoch 81/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7410\n",
      "Epoch 82/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7407\n",
      "Epoch 83/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7402\n",
      "Epoch 84/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7401\n",
      "Epoch 85/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7404\n",
      "Epoch 86/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7406\n",
      "Epoch 87/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7398\n",
      "Epoch 88/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7408\n",
      "Epoch 89/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7404\n",
      "Epoch 90/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7401\n",
      "Epoch 91/100\n",
      "802/802 [==============================] - 3s 3ms/step - loss: 0.5358 - accuracy: 0.7405\n",
      "Epoch 92/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7412\n",
      "Epoch 93/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7406\n",
      "Epoch 94/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7403\n",
      "Epoch 95/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7407\n",
      "Epoch 96/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7413\n",
      "Epoch 97/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7418\n",
      "Epoch 98/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7410\n",
      "Epoch 99/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7412\n",
      "Epoch 100/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7408\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn_a.fit(X_train_scaled, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5598 - accuracy: 0.7282 - 429ms/epoch - 2ms/step\n",
      "Loss: 0.5598382949829102, Accuracy: 0.7282291054725647\n"
     ]
    }
   ],
   "source": [
    "# Eval Model\n",
    "model_loss, model_accuracy = nn_a.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy is not good enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the model\n",
    "nn_a.save(\"trained_a.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying other Hyperparameters\n",
    "We are going to keep the dataset the same and change hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_94 (Dense)            (None, 60)                2640      \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,361\n",
      "Trainable params: 6,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's add another layer to have more interactions between variables\n",
    "nn_b = tf.keras.models.Sequential()\n",
    "nn_b.add(tf.keras.layers.Dense(units=60, activation=\"relu\", input_dim=len(X_train_scaled[0])))\n",
    "nn_b.add(tf.keras.layers.Dense(units=60, activation=\"tanh\"))\n",
    "nn_b.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "nn_b.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "nn_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7429\n",
      "Epoch 2/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5316 - accuracy: 0.7433\n",
      "Epoch 3/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5315 - accuracy: 0.7433\n",
      "Epoch 4/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5312 - accuracy: 0.7431\n",
      "Epoch 5/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7415\n",
      "Epoch 6/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7426\n",
      "Epoch 7/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.7420\n",
      "Epoch 8/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7426\n",
      "Epoch 9/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7433\n",
      "Epoch 10/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5318 - accuracy: 0.7434\n",
      "Epoch 11/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7431\n",
      "Epoch 12/120\n",
      "802/802 [==============================] - 2s 3ms/step - loss: 0.5314 - accuracy: 0.7436\n",
      "Epoch 13/120\n",
      "802/802 [==============================] - 2s 3ms/step - loss: 0.5308 - accuracy: 0.7427\n",
      "Epoch 14/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7422\n",
      "Epoch 15/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7420\n",
      "Epoch 16/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7433\n",
      "Epoch 17/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7422\n",
      "Epoch 18/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7422\n",
      "Epoch 19/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7421\n",
      "Epoch 20/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7437\n",
      "Epoch 21/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7431\n",
      "Epoch 22/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5311 - accuracy: 0.7433\n",
      "Epoch 23/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5305 - accuracy: 0.7429\n",
      "Epoch 24/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7437\n",
      "Epoch 25/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5305 - accuracy: 0.7432\n",
      "Epoch 26/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7432\n",
      "Epoch 27/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7425\n",
      "Epoch 28/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7416\n",
      "Epoch 29/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7424\n",
      "Epoch 30/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7436\n",
      "Epoch 31/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7428\n",
      "Epoch 32/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7431\n",
      "Epoch 33/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7438\n",
      "Epoch 34/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5306 - accuracy: 0.7427\n",
      "Epoch 35/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7436\n",
      "Epoch 36/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5302 - accuracy: 0.7443\n",
      "Epoch 37/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7442\n",
      "Epoch 38/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5304 - accuracy: 0.7434\n",
      "Epoch 39/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5302 - accuracy: 0.7423\n",
      "Epoch 40/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7436\n",
      "Epoch 41/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5296 - accuracy: 0.7440\n",
      "Epoch 42/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7437\n",
      "Epoch 43/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7441\n",
      "Epoch 44/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7423\n",
      "Epoch 45/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7434\n",
      "Epoch 46/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7432\n",
      "Epoch 47/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7439\n",
      "Epoch 48/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7440\n",
      "Epoch 49/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7436\n",
      "Epoch 50/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.7432\n",
      "Epoch 51/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5305 - accuracy: 0.7429\n",
      "Epoch 52/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5302 - accuracy: 0.7431\n",
      "Epoch 53/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5299 - accuracy: 0.7443\n",
      "Epoch 54/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5296 - accuracy: 0.7436\n",
      "Epoch 55/120\n",
      "802/802 [==============================] - 2s 3ms/step - loss: 0.5301 - accuracy: 0.7431\n",
      "Epoch 56/120\n",
      "802/802 [==============================] - 2s 3ms/step - loss: 0.5301 - accuracy: 0.7439\n",
      "Epoch 57/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7432\n",
      "Epoch 58/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7432\n",
      "Epoch 59/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5296 - accuracy: 0.7434\n",
      "Epoch 60/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7428\n",
      "Epoch 61/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7440\n",
      "Epoch 62/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5298 - accuracy: 0.7426\n",
      "Epoch 63/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7422\n",
      "Epoch 64/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7424\n",
      "Epoch 65/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7446\n",
      "Epoch 66/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7440\n",
      "Epoch 67/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5298 - accuracy: 0.7433\n",
      "Epoch 68/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5296 - accuracy: 0.7436\n",
      "Epoch 69/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7433\n",
      "Epoch 70/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5290 - accuracy: 0.7429\n",
      "Epoch 71/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5289 - accuracy: 0.7442\n",
      "Epoch 72/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5296 - accuracy: 0.7435\n",
      "Epoch 73/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5296 - accuracy: 0.7428\n",
      "Epoch 74/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5300 - accuracy: 0.7442\n",
      "Epoch 75/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7438\n",
      "Epoch 76/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7434\n",
      "Epoch 77/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7453\n",
      "Epoch 78/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7439\n",
      "Epoch 79/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5290 - accuracy: 0.7443\n",
      "Epoch 80/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7435\n",
      "Epoch 81/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7440\n",
      "Epoch 82/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7429\n",
      "Epoch 83/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7442\n",
      "Epoch 84/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7439\n",
      "Epoch 85/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7431\n",
      "Epoch 86/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7438\n",
      "Epoch 87/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5293 - accuracy: 0.7429\n",
      "Epoch 88/120\n",
      "802/802 [==============================] - 2s 3ms/step - loss: 0.5291 - accuracy: 0.7440\n",
      "Epoch 89/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7439\n",
      "Epoch 90/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5283 - accuracy: 0.7441\n",
      "Epoch 91/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7445\n",
      "Epoch 92/120\n",
      "802/802 [==============================] - 2s 3ms/step - loss: 0.5288 - accuracy: 0.7436\n",
      "Epoch 93/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7450\n",
      "Epoch 94/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5284 - accuracy: 0.7445\n",
      "Epoch 95/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7442\n",
      "Epoch 96/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7441\n",
      "Epoch 97/120\n",
      "802/802 [==============================] - 2s 3ms/step - loss: 0.5288 - accuracy: 0.7436\n",
      "Epoch 98/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7446\n",
      "Epoch 99/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7436\n",
      "Epoch 100/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7440\n",
      "Epoch 101/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7435\n",
      "Epoch 102/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7435\n",
      "Epoch 103/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7440\n",
      "Epoch 104/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7433\n",
      "Epoch 105/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7433\n",
      "Epoch 106/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7436\n",
      "Epoch 107/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7437\n",
      "Epoch 108/120\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5283 - accuracy: 0.7435\n",
      "Epoch 109/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5287 - accuracy: 0.7432\n",
      "Epoch 110/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7440\n",
      "Epoch 111/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7447\n",
      "Epoch 112/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7438\n",
      "Epoch 113/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7442\n",
      "Epoch 114/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7443\n",
      "Epoch 115/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5283 - accuracy: 0.7445\n",
      "Epoch 116/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7426\n",
      "Epoch 117/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7442\n",
      "Epoch 118/120\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7445\n",
      "Epoch 119/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7440\n",
      "Epoch 120/120\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7445\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn_b.fit(X_train_scaled, y_train, epochs=120, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5650 - accuracy: 0.7245 - 353ms/epoch - 1ms/step\n",
      "Loss: 0.5650394558906555, Accuracy: 0.7244886159896851\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn_b.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "nn_b.save(\"trained_b.h5\")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PCA\n",
    "We have too many features, let's try reducing them to Principal Components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9180860617839217"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def get_explained_variance_ratio(df: pd.DataFrame, n_components: int):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    data = pca.fit_transform(df)\n",
    "    return data, np.asarray(pca.explained_variance_ratio_)\n",
    "\n",
    "N_COMPONENTS = 29\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "data, evr = get_explained_variance_ratio(X_scaled, N_COMPONENTS)\n",
    "X_pca = pd.DataFrame(data, columns=[f\"PC{x+1}\" for x in range(N_COMPONENTS)])\n",
    "\n",
    "plt.plot(np.cumsum(evr))\n",
    "plt.title(\"Explained Variance Ratio Cumulative\")\n",
    "plt.xlabel(\"PCA\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "sum(evr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25664, 29), (8555, 29))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continuing PCA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, random_state=1)\n",
    "# Scale for safety\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Manual Model Test\n",
    "Using PCA, reducing neurons, adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 40)                1200      \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 10)                410       \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,731\n",
      "Trainable params: 1,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "nn_c = tf.keras.models.Sequential()\n",
    "nn_c.add(tf.keras.layers.Dense(units=40, activation=\"relu\", input_dim=len(X_train_scaled[0])))\n",
    "nn_c.add(tf.keras.layers.Dense(units=10, activation=\"relu\"))\n",
    "nn_c.add(tf.keras.layers.Dense(units=10, activation=\"relu\"))\n",
    "nn_c.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "nn_c.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "nn_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5887 - accuracy: 0.7096\n",
      "Epoch 2/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5557 - accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5538 - accuracy: 0.7306\n",
      "Epoch 5/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.7304\n",
      "Epoch 6/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.7315\n",
      "Epoch 7/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7316\n",
      "Epoch 8/100\n",
      "802/802 [==============================] - 2s 2ms/step - loss: 0.5498 - accuracy: 0.7318\n",
      "Epoch 9/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5496 - accuracy: 0.7309\n",
      "Epoch 10/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5488 - accuracy: 0.7318\n",
      "Epoch 11/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7329\n",
      "Epoch 12/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7316\n",
      "Epoch 13/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7334\n",
      "Epoch 14/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7335\n",
      "Epoch 15/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7314\n",
      "Epoch 16/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7334\n",
      "Epoch 17/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7335\n",
      "Epoch 18/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5462 - accuracy: 0.7350\n",
      "Epoch 19/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5463 - accuracy: 0.7337\n",
      "Epoch 20/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7345\n",
      "Epoch 21/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7331\n",
      "Epoch 22/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7347\n",
      "Epoch 23/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7339\n",
      "Epoch 24/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7355\n",
      "Epoch 25/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7333\n",
      "Epoch 26/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7343\n",
      "Epoch 27/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7347\n",
      "Epoch 28/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7353\n",
      "Epoch 29/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7355\n",
      "Epoch 30/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7358\n",
      "Epoch 31/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7361\n",
      "Epoch 32/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7369\n",
      "Epoch 33/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7356\n",
      "Epoch 34/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7365\n",
      "Epoch 35/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7351\n",
      "Epoch 36/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7365\n",
      "Epoch 37/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7370\n",
      "Epoch 38/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7361\n",
      "Epoch 39/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7368\n",
      "Epoch 40/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7368\n",
      "Epoch 41/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7368\n",
      "Epoch 42/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7374\n",
      "Epoch 43/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7365\n",
      "Epoch 44/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7359\n",
      "Epoch 45/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7363\n",
      "Epoch 46/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7372\n",
      "Epoch 47/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7361\n",
      "Epoch 48/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7371\n",
      "Epoch 49/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7369\n",
      "Epoch 50/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7365\n",
      "Epoch 51/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7368\n",
      "Epoch 52/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7371\n",
      "Epoch 53/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7374\n",
      "Epoch 54/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7375\n",
      "Epoch 55/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7376\n",
      "Epoch 56/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7369\n",
      "Epoch 57/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7369\n",
      "Epoch 58/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5410 - accuracy: 0.7383\n",
      "Epoch 59/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7358\n",
      "Epoch 60/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5409 - accuracy: 0.7376\n",
      "Epoch 61/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7364\n",
      "Epoch 62/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7383\n",
      "Epoch 63/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5409 - accuracy: 0.7368\n",
      "Epoch 64/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7379\n",
      "Epoch 65/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7382\n",
      "Epoch 66/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7368\n",
      "Epoch 67/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7377\n",
      "Epoch 68/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.7372\n",
      "Epoch 69/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7365\n",
      "Epoch 70/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.7375\n",
      "Epoch 71/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7379\n",
      "Epoch 72/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5403 - accuracy: 0.7384\n",
      "Epoch 73/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7374\n",
      "Epoch 74/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.7381\n",
      "Epoch 75/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7384\n",
      "Epoch 76/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7371\n",
      "Epoch 77/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7385\n",
      "Epoch 78/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5402 - accuracy: 0.7375\n",
      "Epoch 79/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7375\n",
      "Epoch 80/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.7378\n",
      "Epoch 81/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7375\n",
      "Epoch 82/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5394 - accuracy: 0.7369\n",
      "Epoch 83/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7384\n",
      "Epoch 84/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7374\n",
      "Epoch 85/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7373\n",
      "Epoch 86/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7373\n",
      "Epoch 87/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7377\n",
      "Epoch 88/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7376\n",
      "Epoch 89/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.7376\n",
      "Epoch 90/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7389\n",
      "Epoch 91/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7373\n",
      "Epoch 92/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7372\n",
      "Epoch 93/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7373\n",
      "Epoch 94/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7375\n",
      "Epoch 95/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5394 - accuracy: 0.7382\n",
      "Epoch 96/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.7377\n",
      "Epoch 97/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7369\n",
      "Epoch 98/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7375\n",
      "Epoch 99/100\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7383\n",
      "Epoch 100/100\n",
      "802/802 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7371\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn_c.fit(X_train_scaled, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5569 - accuracy: 0.7281 - 447ms/epoch - 2ms/step\n",
      "Loss: 0.5568825602531433, Accuracy: 0.7281122207641602\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn_c.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "nn_c.save(\"trained_c.h5\")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
      "<function create_model at 0x13ca44560>\n",
      "<keras_tuner.tuners.hyperband.Hyperband object at 0x10f151050>\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def create_model(hp: kt.HyperParameters) -> tf.keras.Model:\n",
    "    \"\"\"Uses the HyperParameters from a Keras Tuner and returns a Keras Model\"\"\"\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "\n",
    "    nn_model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            units=hp.Int(\n",
    "                'first_units',\n",
    "                min_value=1,\n",
    "                max_value=10,\n",
    "                step=2,\n",
    "            ),\n",
    "                activation=activation,\n",
    "                input_dim=len(X_train_scaled[0])\n",
    "        ))\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        nn_model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                units=hp.Int(\n",
    "                    'units_' + str(i),\n",
    "                    min_value=1,\n",
    "                    max_value=10,\n",
    "                    step=2,\n",
    "                ),\n",
    "                activation=activation\n",
    "            ))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    nn_model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return nn_model\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2\n",
    ")\n",
    "print(create_model)\n",
    "print(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 00m 33s]\n",
      "val_accuracy: 0.7240210175514221\n",
      "\n",
      "Best val_accuracy So Far: 0.726475715637207\n",
      "Total elapsed time: 00h 15m 02s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# applying the tuner to the PCA values\n",
    "tuner.search(X_train_scaled, y_train, epochs=20, validation_data=(X_test_scaled, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'first_units': 7, 'num_layers': 4, 'units_0': 7, 'units_1': 7, 'units_2': 5, 'units_3': 9, 'units_4': 7, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0014'}\n"
     ]
    }
   ],
   "source": [
    "# getting the best hyper\n",
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "print(best_hyper.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5572 - accuracy: 0.7265 - 793ms/epoch - 3ms/step\n",
      "Loss: 0.5571862459182739, Accuracy: 0.726475715637207\n"
     ]
    }
   ],
   "source": [
    "# Getting the best model\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_accuracy = best_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "612/612 [==============================] - 2s 2ms/step - loss: 0.5533 - accuracy: 0.7476\n",
      "Epoch 2/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5530 - accuracy: 0.7486\n",
      "Epoch 3/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5522 - accuracy: 0.7483\n",
      "Epoch 4/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5519 - accuracy: 0.7475\n",
      "Epoch 5/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5519 - accuracy: 0.7478\n",
      "Epoch 6/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5516 - accuracy: 0.7486\n",
      "Epoch 7/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5510 - accuracy: 0.7487\n",
      "Epoch 8/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5508 - accuracy: 0.7493\n",
      "Epoch 9/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5509 - accuracy: 0.7483\n",
      "Epoch 10/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5504 - accuracy: 0.7502\n",
      "Epoch 11/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5506 - accuracy: 0.7491\n",
      "Epoch 12/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7494\n",
      "Epoch 13/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5499 - accuracy: 0.7501\n",
      "Epoch 14/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7498\n",
      "Epoch 15/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7489\n",
      "Epoch 16/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7497\n",
      "Epoch 17/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7502\n",
      "Epoch 18/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5493 - accuracy: 0.7497\n",
      "Epoch 19/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7493\n",
      "Epoch 20/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5489 - accuracy: 0.7489\n",
      "Epoch 21/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7482\n",
      "Epoch 22/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.7497\n",
      "Epoch 23/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5478 - accuracy: 0.7493\n",
      "Epoch 24/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7493\n",
      "Epoch 25/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7492\n",
      "Epoch 26/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7493\n",
      "Epoch 27/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7486\n",
      "Epoch 28/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7492\n",
      "Epoch 29/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7489\n",
      "Epoch 30/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7492\n",
      "Epoch 31/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7486\n",
      "Epoch 32/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7489\n",
      "Epoch 33/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7491\n",
      "Epoch 34/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7488\n",
      "Epoch 35/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7476\n",
      "Epoch 36/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7490\n",
      "Epoch 37/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7490\n",
      "Epoch 38/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7488\n",
      "Epoch 39/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7491\n",
      "Epoch 40/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7492\n",
      "Epoch 41/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7482\n",
      "Epoch 42/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7480\n",
      "Epoch 43/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7484\n",
      "Epoch 44/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7481\n",
      "Epoch 45/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7483\n",
      "Epoch 46/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7480\n",
      "Epoch 47/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7482\n",
      "Epoch 48/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7481\n",
      "Epoch 49/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7488\n",
      "Epoch 50/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7492\n",
      "Epoch 51/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7492\n",
      "Epoch 52/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7491\n",
      "Epoch 53/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7486\n",
      "Epoch 54/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7487\n",
      "Epoch 55/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7484\n",
      "Epoch 56/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7497\n",
      "Epoch 57/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7498\n",
      "Epoch 58/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7488\n",
      "Epoch 59/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7501\n",
      "Epoch 60/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7497\n",
      "Epoch 61/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7499\n",
      "Epoch 62/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7502\n",
      "Epoch 63/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7499\n",
      "Epoch 64/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7498\n",
      "Epoch 65/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7495\n",
      "Epoch 66/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7497\n",
      "Epoch 67/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7505\n",
      "Epoch 68/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7499\n",
      "Epoch 69/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7503\n",
      "Epoch 70/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7492\n",
      "Epoch 71/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7501\n",
      "Epoch 72/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7492\n",
      "Epoch 73/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7499\n",
      "Epoch 74/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7495\n",
      "Epoch 75/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7499\n",
      "Epoch 76/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7499\n",
      "Epoch 77/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7498\n",
      "Epoch 78/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7511\n",
      "Epoch 79/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7486\n",
      "Epoch 81/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7502\n",
      "Epoch 82/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7506\n",
      "Epoch 83/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7498\n",
      "Epoch 84/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7491\n",
      "Epoch 85/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7508\n",
      "Epoch 86/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7496\n",
      "Epoch 87/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7503\n",
      "Epoch 88/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7504\n",
      "Epoch 89/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7496\n",
      "Epoch 90/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7498\n",
      "Epoch 91/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7490\n",
      "Epoch 92/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7496\n",
      "Epoch 93/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7494\n",
      "Epoch 94/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7498\n",
      "Epoch 95/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7494\n",
      "Epoch 96/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7501\n",
      "Epoch 97/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7494\n",
      "Epoch 98/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7499\n",
      "Epoch 99/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7494\n",
      "Epoch 100/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13aa3bc90>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model with more epochs\n",
    "best_model.fit(X_train_scaled, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 0s - loss: 0.5435 - accuracy: 0.7391 - 249ms/epoch - 1ms/step\n",
      "Loss: 0.5435408353805542, Accuracy: 0.7391170859336853\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = best_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using IQR-filtered Data\n",
    "We won't give up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26093, 29), 0.9083105427341529)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = encoded_df.drop(outliers_iqr.index)\n",
    "y = df[\"IS_SUCCESSFUL\"].values\n",
    "X = df.drop([\"IS_SUCCESSFUL\"], axis=1).values\n",
    "\n",
    "def get_explained_variance_ratio(df: pd.DataFrame, n_components: int):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    data = pca.fit_transform(df)\n",
    "    return data, np.asarray(pca.explained_variance_ratio_)\n",
    "\n",
    "N_COMPONENTS = 29\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "data, evr = get_explained_variance_ratio(X_scaled, N_COMPONENTS)\n",
    "X_pca = pd.DataFrame(data, columns=[f\"PC{x+1}\" for x in range(N_COMPONENTS)])\n",
    "X_pca.shape, sum(evr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19569, 29), (6524, 29))"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, random_state=1)\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72 Complete [00h 00m 28s]\n",
      "val_accuracy: 0.7401900887489319\n",
      "\n",
      "Best val_accuracy So Far: 0.7420294284820557\n",
      "Total elapsed time: 00h 24m 19s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Tuner Search with the IQR-filtered data\n",
    "tuner.search(X_train_scaled, y_train, epochs=20, validation_data=(X_test_scaled, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'first_units': 3, 'num_layers': 3, 'units_0': 5, 'units_1': 7, 'units_2': 7, 'units_3': 9, 'units_4': 5, 'units_5': 5, 'tuner/epochs': 20, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "print(best_hyper.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.5611 - accuracy: 0.7420 - 719ms/epoch - 4ms/step\n",
      "Loss: 0.5610514879226685, Accuracy: 0.7420294284820557\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_accuracy = best_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7494\n",
      "Epoch 2/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7496\n",
      "Epoch 3/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7498\n",
      "Epoch 4/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7497\n",
      "Epoch 5/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7496\n",
      "Epoch 6/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7511\n",
      "Epoch 7/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7493\n",
      "Epoch 8/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7494\n",
      "Epoch 9/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7507\n",
      "Epoch 10/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7497\n",
      "Epoch 11/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7501\n",
      "Epoch 12/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7490\n",
      "Epoch 13/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7496\n",
      "Epoch 14/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7506\n",
      "Epoch 15/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7502\n",
      "Epoch 16/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7501\n",
      "Epoch 17/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7496\n",
      "Epoch 18/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7495\n",
      "Epoch 19/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7499\n",
      "Epoch 20/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7495\n",
      "Epoch 21/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7496\n",
      "Epoch 22/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7501\n",
      "Epoch 23/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7493\n",
      "Epoch 25/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7496\n",
      "Epoch 26/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7499\n",
      "Epoch 27/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7507\n",
      "Epoch 28/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7490\n",
      "Epoch 29/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7501\n",
      "Epoch 30/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7496\n",
      "Epoch 31/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7502\n",
      "Epoch 32/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7491\n",
      "Epoch 33/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7490\n",
      "Epoch 34/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7498\n",
      "Epoch 36/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7497\n",
      "Epoch 37/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7497\n",
      "Epoch 38/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7508\n",
      "Epoch 39/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7501\n",
      "Epoch 40/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7491\n",
      "Epoch 41/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7502\n",
      "Epoch 42/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7496\n",
      "Epoch 43/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7489\n",
      "Epoch 44/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7488\n",
      "Epoch 45/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7495\n",
      "Epoch 46/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7499\n",
      "Epoch 47/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7498\n",
      "Epoch 48/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7498\n",
      "Epoch 49/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7499\n",
      "Epoch 50/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7499\n",
      "Epoch 51/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7499\n",
      "Epoch 52/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7497\n",
      "Epoch 53/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7499\n",
      "Epoch 54/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7494\n",
      "Epoch 55/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7493\n",
      "Epoch 56/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7491\n",
      "Epoch 57/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7490\n",
      "Epoch 58/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7490\n",
      "Epoch 59/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7493\n",
      "Epoch 60/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7499\n",
      "Epoch 61/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7495\n",
      "Epoch 62/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7501\n",
      "Epoch 63/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7497\n",
      "Epoch 64/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7492\n",
      "Epoch 65/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7492\n",
      "Epoch 66/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7498\n",
      "Epoch 67/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7503\n",
      "Epoch 68/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7495\n",
      "Epoch 69/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7495\n",
      "Epoch 70/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7501\n",
      "Epoch 71/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7491\n",
      "Epoch 72/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7489\n",
      "Epoch 73/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7495\n",
      "Epoch 74/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7495\n",
      "Epoch 75/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7492\n",
      "Epoch 76/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7493\n",
      "Epoch 77/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7497\n",
      "Epoch 78/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7499\n",
      "Epoch 79/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7498\n",
      "Epoch 80/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7501\n",
      "Epoch 81/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7498\n",
      "Epoch 82/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7495\n",
      "Epoch 83/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7505\n",
      "Epoch 84/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7502\n",
      "Epoch 85/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7503\n",
      "Epoch 86/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7492\n",
      "Epoch 87/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7499\n",
      "Epoch 88/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7495\n",
      "Epoch 89/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7487\n",
      "Epoch 90/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7492\n",
      "Epoch 91/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7498\n",
      "Epoch 92/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7492\n",
      "Epoch 93/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7492\n",
      "Epoch 94/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7499\n",
      "Epoch 95/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7499\n",
      "Epoch 96/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7495\n",
      "Epoch 97/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7505\n",
      "Epoch 98/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7494\n",
      "Epoch 99/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7507\n",
      "Epoch 100/100\n",
      "612/612 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13bc2a910>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_scaled, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 0s - loss: 0.5454 - accuracy: 0.7371 - 233ms/epoch - 1ms/step\n",
      "Loss: 0.5454042553901672, Accuracy: 0.7371244430541992\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = best_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.14 64-bit ('3.7.14')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "018e100c3342e229243fa047afbfad47714c1292d6b5876231712c46861f9d60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
